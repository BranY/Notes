<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.1.1 (456663)"/><meta name="altitude" content="11.24942874908447"/><meta name="author" content="杨文家"/><meta name="created" content="2018-05-20 11:29:21 +0000"/><meta name="latitude" content="30.19546987530475"/><meta name="longitude" content="120.1919971339509"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2018-05-20 11:45:23 +0000"/><title>wide &amp; deep etc</title></head><body><div style="orphans: 2; widows: 2; "><font color="#1a1a1a" style="font-size: 18px;" face="Helvetica Neue"><span style="caret-color: rgb(26, 26, 26); white-space: pre-wrap;">Wide &amp; Deep </span></font></div><div style="orphans: 2; widows: 2; "><font color="#1a1a1a" face="-apple-system, system-ui, Helvetica Neue, PingFang SC, Microsoft YaHei, Source Han Sans SC, Noto Sans CJK SC, WenQuanYi Micro Hei, sans-serif"><span style="caret-color: rgb(26, 26, 26); font-size: 16px; white-space: pre-wrap;"><br/></span></font></div><div><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 16px; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;-en-paragraph:true;">Memory：交叉特征的线性模型的优点。能用少量的参数记住一些硬规则，只要发生过的情况都能显式地学出来。但是没发生过的情况学不出来，更高阶的组合特征的作用也学不出来。
</span></div><div style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 16px; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); margin-top: 1em; margin-bottom: 1em;"><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 16px; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);-en-paragraph:true;">Generalisation：深度模型的优点。通过表达性学习，能学习出没发生过的item query搭配的情况。但容易过度泛化，特别是行为数据稀疏的时候，容易推荐出很多不相关的商品。毕竟dense embedding会对所有商品都做出非零预测。它只适合捕捉一些实际有用的高阶特征，对于低阶特征如果显式学习的话，需要的参数量比浅层模型多得多，不现实。
</span></div><div><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 16px; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;-en-paragraph:true;">W&amp;D尝试把浅层和深层模型有机结合起来，以解决上述问题。Wide部分是人工的交叉特征接LR，Deep部分是输入层接embedding层再接几个全连接层。
</span></div><div><img src="wide%20&amp;%20deep%20etc.resources/FBC45A6D-1234-423C-91BD-736DBE8BB799.jpg" height="301" width="1180"/></div><div><font style="font-size: 18px;">FNN：</font></div><div><br/></div><div><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 16px; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;-en-paragraph:true;">ctr的特征是离散，高维且稀疏的，需要embedding后才能用nn学习。该模型主要的特色是Embedding层用FM初始化，即每个特征对应一个偏置项wi和一个k维向量vi。然后参数向量再随着训练不断学习调整
</span></div><div><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 16px; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;-en-paragraph:true;"><br/></span></div><div><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 16px; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;-en-paragraph:true;">假设每个field的类别特征都只有一个1值，其余为0值，即可进行one-hot编码，然后做embedding，Dense RealLayer里每个Field对应的参数就是该Field那个不为0的变量对应的FM里的偏置项wi和k维隐向量vi。简单说模型第一层到第二层之间其实是普通的全连接层，而为0的输入变量对Dense RealLayer里的隐单元值不做贡献。
</span></div><div style="text-align: center; "><img src="wide%20&amp;%20deep%20etc.resources/4A1FD68E-04B3-47F8-8947-1DC399804AEE.png" height="727" width="1308"/></div><div><br/></div><div style="text-align: center; "><br/></div><div><br/></div><div><br/></div></body></html>