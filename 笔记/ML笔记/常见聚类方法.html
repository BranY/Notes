<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.2 (456745)"/><meta name="altitude" content="11.38462257385254"/><meta name="author" content="杨文家"/><meta name="created" content="2018-05-19 12:45:35 +0000"/><meta name="latitude" content="30.19547523312549"/><meta name="longitude" content="120.1919652606613"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2018-06-06 15:03:43 +0000"/><title>常见聚类方法</title></head><body><div>常见聚类算法：层次聚类（AGNES自底向上）、基于划分的聚类（k-means)、密度聚类，基于网格的聚类、基于模型的方法</div><div><br/></div><ul><li><div><span style="color: rgb(255, 38, 0);">层次聚类</span>：<span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">主要有两种类型：合并的层次聚类和分裂的层次聚类。前者是一种</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">自底向上的层次聚类算法</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">，从最底层开始，每一次通过合并最相似的聚类来形成上一层次中的聚类，整个当全部数据点都合并到一个聚类的时候停止或者达到某个终止条件而结束，大部分层次聚类都是采用这种方法处理。后者是</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">采用自顶向下的方法</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">，从一个包含全部数据点的聚类开始，然后把根节点分裂为一些子聚类，每个子聚类再递归地继续往下分裂，直到出现只包含一个数据点的单节点聚类出现，即每个聚类中仅包含一个数据点。</span></div></li><ul><li><div><span style="color: rgb(79, 79, 79); font-weight: bold;">优点</span><span style="color: rgb(79, 79, 79);">：</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">可解释性好、</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">层次的粒度可控</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">；能产生高质量的聚类，也会应用在上面说的</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">先取K比较大的K-means后的合并阶段</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">；还有对于K-means不</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">能解决的非球形族</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">就可以解决了。 </span></div></li><li><div><span style="color: rgb(79, 79, 79); font-weight: bold;">缺点</span><span style="color: rgb(79, 79, 79);">：时间复杂度高，本身是一种贪心算法，一步错步步错</span></div></li></ul></ul><div><br/></div><ul><li><div><span style="color: rgb(255, 38, 0);">划分聚类</span>：<span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">聚类效果就是“类内的点都足够近，类间的点都足够远”。首先你要确定这堆散点最后聚成几类，然后挑选几个点作为初始中心点，再然后依据预先定好的启发式算法给数据点做迭代重置，直到最后到达“类内的点都足够近，类间的点都足够远”的目标效果。</span></div></li><ul><li><div><span style="color: rgb(79, 79, 79); font-weight: bold;">优点</span><span style="color: rgb(79, 79, 79);">：</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">对于大型数据集也是简单高效、时间复杂度、空间复杂度低</span></div></li><li><div><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-weight: bold;">缺点</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;;">：</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">最重要是</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">数据集大时结果容易局部最优</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">；需要预先设定K值，</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">对最先的K个点选取很敏感</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">；</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">对噪声和离群值非常敏感</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">；只用于</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">numerical类型数据</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">；不能解决非凸数据（形状不规则的族类，如花瓣状等不规则形状）。</span></div></li><li><div><font color="#4f4f4f">K值的选择方法：</font></div></li><ul><li><div><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;">数据的先验知识，或者数据进行简单分析能得到</span></div></li><li><div><font color="#1a1a1a"><span style="caret-color: rgb(26, 26, 26);">对数据的观察或者任务本身的需要</span></font></div></li><li><div><font color="#1a1a1a"><span style="caret-color: rgb(26, 26, 26);">交叉验证的方法</span></font></div></li><li><div><font color="#1a1a1a"><span style="caret-color: rgb(26, 26, 26);">通过层次聚类辅助得到k值，<span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;">即基于合并或分裂的思想，在一定情况下停止从而获得K</span></span></font></div></li><li><div><span style="color: rgb(0, 0, 0); font-family: &quot;PingFang SC&quot;; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;">基于采样的算法：即对样本采样，分别做聚类；根据这些结果的相似性确定K</span></div></li></ul><li><div><span style="color: rgb(79, 79, 79);">改进：</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">对初始值的设置很敏感，所以有了k-means++；</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">对噪声和离群点敏感，所以有了k-medians; 只能初级数值型数据</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">，所以有了k-models+；</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">不能解决非凸（non-convex）数据，所以有了</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">kernel k-means</span></div></li></ul></ul><div><br/></div><ul><li><div><span style="color: rgb(255, 38, 0);">密度聚类（DBSCAN）</span>：<span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;;">可以</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">解决不了不规则形状的聚类，该方法同时也对噪声数据的处理比较好。其原理简单说画圈儿，其中要定义两个参数，一个是</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">圈儿的最大半径</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">，一个是</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">一个圈儿里最少应容纳几个点</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">。只要邻近区域的密度（对象或数据点的数目）超过某个阈值，就继续聚类,最后在一个圈里的，就是一个类。</span></div></li><ul><li><div>优点：<span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">对噪声不敏感；能发现任意形状的聚类</span></div></li><li><div><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;;">缺点：</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">聚类的结果与参数有很大的关系；DBSCAN用固定参数识别聚类，但当聚类的稀疏程度不同时，相同的判定标准可能会破坏聚类的自然结构，即较稀的聚类会被划分为多个类或密度较大且离得较近的类会被合并成一个聚类</span></div></li></ul></ul><div><br/></div><ul><li><div><span style="color: rgb(255, 38, 0);">网格聚类</span>：<span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">基于网络的方法：这类方法的原理就是将数据空间划分为网格单元，将数据对象集映射到网格单元中，并计算每个单元的密度。根据预设的阈值判断每个网格单元是否为高密度单元，由邻近的稠密单元组形成”类“。</span></div></li><ul><li><div><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;;">优点：</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">速度很快，因为其速度与数据对象的个数无关，而只依赖于数据空间中每个维上单元的个数。</span></div></li><li><div><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;;">缺点：</span><span style="orphans: 2; widows: 2; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal;">参数敏感、无法处理不规则分布的数据、维数灾难等；这种算法效率的提高是以聚类结果的精确性为代价的。经常与基于密度的算法结合使用</span></div></li></ul></ul><div><br/></div><ul><li><div><span style="color: rgb(255, 38, 0);">模型聚类</span>：<span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">为每簇假定了一个模型，寻找数据对给定模型的最佳拟合，这一类方法主要是指基于概率模型的方法和基于神经网络模型的方法，尤其以基于概率模型的方法居多。这里的概率模型主要指概率生成模型，同一”类“的数据属于同一种概率分布，即假设数据是根据潜在的概率分布生成的</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">。其中最典型、也最常用的方法就是高斯混合模型（GMM，Gaussian Mixture Models）</span></div></li><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">优点是：</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">对”类“的划分不那么”坚硬“，而是以概率形式表现，每一类的特征也可以用参数来表达。</span></div></li><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">缺点是：</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">执行效率不高，特别是分布数量很多并且数据量很少的时候。</span></div></li></ul></ul><div><br/></div></body></html>