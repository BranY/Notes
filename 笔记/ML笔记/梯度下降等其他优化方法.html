<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.1.1 (456663)"/><meta name="altitude" content="11.38462257385254"/><meta name="author" content="杨文家"/><meta name="created" content="2018-05-19 12:46:52 +0000"/><meta name="latitude" content="30.19547523312549"/><meta name="longitude" content="120.1919652606613"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2018-05-28 09:53:57 +0000"/><title>梯度下降等其他优化方法</title></head><body><div>方差和偏差， L1和L2正则化, 梯度（这块看看李宏毅老师的就行）</div><div><br/></div><div><span style="font-size: 18px;">模型正则化</span></div><div>正则化<span style="color: rgb(65, 63, 63);">即罚函数，该项对模型向量进行“惩罚”，从而避免单纯最小二乘问题的过拟合问题。训练的目的是最小化目标函数，则C越小，意味着惩罚越小，分类间隔也就越小，分类错误也就越少。</span></div><div><br style="color: rgb(65, 63, 63);"/></div><div><span style="color: rgb(65, 63, 63);">正则化项本质上是一种先验信息，整个最优化问题从贝叶斯观点来看是一种贝叶斯最大后验估计，其中正则化项对应后验估计中的先验信息，损失函数对应后验估计中的似然函数，两者的乘积即对应贝叶斯最大后验估计的形式，如果你将这个贝叶斯最大后验估计的形式取对数，即进行极大似然估计，你就会发现问题立马变成了损失函数+正则化项的最优化问题形式。</span></div><div><br style="color: rgb(65, 63, 63);"/></div><ul><li><div><span style="color: rgb(65, 63, 63);">避免出现过拟合（over-fitting）。经验风险最小化 + 正则化项 = 结构风险最小化。</span></div></li><li><div><span style="color: rgb(65, 63, 63);">L1范数是指向量中各个元素绝对值之和，</span><span style="color: rgb(255, 38, 0);">用于特征选择;</span></div></li><li><div><span style="color: rgb(65, 63, 63);">L1正则化将系数的l1范数作为惩罚项加到损失函数上。</span></div></li></ul><div><br style="color: rgb(65, 63, 63);"/></div><ul><li><div><span style="color: rgb(65, 63, 63);">L2范数是指向量各元素的平方和然后求平方根，</span><span style="color: rgb(255, 38, 0);">用于 防止过拟合，提升模型的泛化能力</span><span style="color: rgb(65, 63, 63);">。</span></div></li><li><div><span style="color: rgb(65, 63, 63);">L2正则化将系数向量的L2范数添加到了损失函数中。L2惩罚项中系数是二次方的。</span></div></li></ul><div><br style="color: rgb(65, 63, 63);"/></div><div><span style="color: rgb(65, 63, 63);">L1与L2区别：</span></div><ul><li><div><span style="color: rgb(65, 63, 63);">使用L1可以得到稀疏的权值；用L2可以得到平滑的权值。</span></div></li><li><div><span style="color: rgb(65, 63, 63);">L1优点是能够获得</span><span style="color: rgb(255, 38, 0);">sparse</span><span style="color: rgb(65, 63, 63);">模型，对于large-scale的问题来说这一点很重要，</span><span style="color: rgb(255, 38, 0);">因为可以减少存储空间</span><span style="color: rgb(65, 63, 63);">。缺点是加入L1后目标函数在原点不可导，需要做特殊处理。</span></div></li><li><div><span style="color: rgb(65, 63, 63);">L2优点是实现简单，能够起到正则化的作用。</span><span style="color: rgb(255, 38, 0);">缺点就是L1的优点：无法获得sparse模型</span><span style="color: rgb(65, 63, 63);">。</span></div></li></ul><div><br/></div><div><span style="font-size: 18px;">避免过拟合的方法：</span></div><ul><li><div><span style="font-size: 18px;">early stopping</span><span style="font-size: 14px;">：</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。 </span></div></li></ul><div><br/></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font style="font-size: 14px;"><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">Early stopping方法的具体做法是，在每一个Epoch结束时（一个Epoch集为对所有的训练数据的一轮遍历）计算validation data的accuracy，</span><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(79, 79, 79); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">当accuracy不再提高时，就停止训练</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">。这种做法很符合直观感受，因为accurary都不再提高了，在继续训练也是无益的，只会提高训练的时间。</span></font></span></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font style="font-size: 14px;"><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">那么该做法的一个重点便是怎样才认为validation accurary不再提高了呢？</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">并不是说validation accuracy一降下来便认为不再提高了，因为可能经过这个Epoch后，accuracy降低了，但是随后的Epoch又让accuracy又上去了，</span><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(79, 79, 79); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">所以不能根据一两次的连续降低就判断不再提高</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">。一般的做法是，在训练的过程中，记录到目前为止最好的validation accuracy，当连续10次Epoch（或者更多次）没达到最佳accuracy时，则可以认为accuracy不再提高了。此时便可以停止迭代了（Early Stopping）。这种策略也称为“No-improvement-in-n”，n即Epoch的次数，可以根据实际情况取，如10、20、30……</span></font></span></div><div><br/></div><ul><li><div><span style="font-size: 18px;">数据集扩增</span>：<font style="font-size: 18px;" face="Helvetica Neue"><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(221, 75, 57); font-variant-caps: normal; font-variant-ligatures: normal;">数据</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(84, 84, 84); font-variant-caps: normal; font-variant-ligatures: normal;">和特征决定了机器学习的</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(221, 75, 57); font-variant-caps: normal; font-variant-ligatures: normal;">上限</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(84, 84, 84); font-variant-caps: normal; font-variant-ligatures: normal;">，而</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(221, 75, 57); font-variant-caps: normal; font-variant-ligatures: normal;">模型</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(84, 84, 84); font-variant-caps: normal; font-variant-ligatures: normal;">和算法的应用</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(221, 75, 57); font-variant-caps: normal; font-variant-ligatures: normal;">只是</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(84, 84, 84); font-variant-caps: normal; font-variant-ligatures: normal;">让我们逼近这个</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(221, 75, 57); font-variant-caps: normal; font-variant-ligatures: normal;">上限</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 18px; font-family: &quot;Helvetica Neue&quot;; color: rgb(84, 84, 84); font-variant-caps: normal; font-variant-ligatures: normal;">。</span></font></div></li></ul><div><font style="font-size: 14px;" color="#545454"><span style="caret-color: rgb(84, 84, 84); font-size: 14px; color: rgb(84, 84, 84);">          <span style="font-size: 14px; color: rgb(84, 84, 84); font-family: &quot;Helvetica Neue&quot;;"> 常见方法</span></span></font></div><ul><ul><li><div><font style="font-size: 14px;" face="Helvetica Neue" color="#545454"><span style="caret-color: rgb(84, 84, 84); font-size: 14px; color: rgb(84, 84, 84); font-family: &quot;Helvetica Neue&quot;;">从数据源头采集更多数据</span></font></div></li><li><div><font style="font-size: 14px;" face="Helvetica Neue" color="#545454"><span style="caret-color: rgb(84, 84, 84); font-size: 14px; color: rgb(84, 84, 84); font-family: &quot;Helvetica Neue&quot;;">复制原有数据并加上噪声</span></font></div></li><li><div><font style="font-size: 14px;" face="Helvetica Neue" color="#545454"><span style="caret-color: rgb(84, 84, 84); font-size: 14px; color: rgb(84, 84, 84); font-family: &quot;Helvetica Neue&quot;;">重采样</span></font></div></li><li><div><font style="font-size: 14px;" face="Helvetica Neue" color="#545454"><span style="caret-color: rgb(84, 84, 84); font-size: 14px; color: rgb(84, 84, 84); font-family: &quot;Helvetica Neue&quot;;">根据当前数据集估计数据分布参数，使用新的分布产生更多的数据</span></font></div></li></ul></ul><div><br/></div><ul><li><div><span style="font-size: 18px;">正则化：</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 18px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">正则项是为了降低模型的复杂度，从而避免模型区过分拟合训练数据，包括噪声与异常点</span></span></div></li><ul><li><div><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">L2正则项起到使得参数</span><span style="box-sizing: border-box; outline: 0px; font-size: 14px; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: 0px; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; word-break: break-all; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); top: 0px; clip: rect(1px, 1px, 1px, 1px); overflow: hidden !important; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;">w</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">变小加剧的效果，但是为什么可以防止过拟合呢？一个通俗的理解便是：<span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">更小的参数值</span></span><span style="box-sizing: border-box; outline: 0px; font-size: 14px; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: 0px; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; word-break: break-all; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; top: 0px; clip: rect(1px, 1px, 1px, 1px); background-color: rgb(255, 250, 165); overflow: hidden !important; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;-evernote-highlight:true;">w</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;"><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">意味着模型的复杂度更低</span>，对训练数据的拟合刚刚好（奥卡姆剃刀），不会过分拟合训练数据，从而使得不会过拟合，以提高模型的泛化能力。</span></div></li><li><div><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">正则化即是</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">假设模型参数服从先验概率，即为模型参数添加先验</span></span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">，只是不同的正则化方式的先验分布是不一样的。这样就规定了参数的分布，使得模型的复杂度降低（试想一下，限定条件多了，是不是模型的复杂度降低了呢），</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">这样模型对于噪声与异常点的抗干扰性的能力增强，从而提高模型的泛化能力</span></span></div></li><li><div><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">从</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">贝叶斯学派</span></span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">来看：加了先验，在数据少的时候，先验知识可以防止过拟合；</span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-ligatures: normal;">从</span><span style="font-size: 14px; orphans: 2; widows: 2;"><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-ligatures: normal;">频率学派</span></span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-ligatures: normal;">来看：正则项限定了参数的取值，从而提高了模型的稳定性，而稳定性强的模型不会过拟合，即控制模型空间。 </span></div></li><li><div><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">正则化项的引入，在训练（最小化cost）的过程中，当某一维的特征所对应的权重过大时，而此时模型的预测和真实数据之间距离很小，通过规则化项就可以使整体的cost取较大的值，从而，在训练的过程中避免了去选择那些某一维（或几维）特征的权重过大的情况，即过分依赖某一维（或几维）的特征</span></div></li><li><div><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; widows: 2; word-spacing: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">L2与L1的区别在于: L1正则是</span><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">拉普拉斯先验</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; widows: 2; word-spacing: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">，而L2正则则是</span><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">高斯先验</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; widows: 2; word-spacing: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">。它们都是服从均值为0，协方差为</span><span style="box-sizing: border-box; outline: 0px; font-size: 16px; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: 0px; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; word-break: break-all; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.424em; color: rgb(51, 51, 51); font-family: STIXGeneral-Regular; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;">1/</span><span style="box-sizing: border-box; outline: 0px; font-size: 16px; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: 0px; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; word-break: break-all; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; color: rgb(51, 51, 51); font-family: STIXGeneral-Italic; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;">λ</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">。当</span><span style="box-sizing: border-box; outline: 0px; font-size: 14px; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: 0px; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; word-break: break-all; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); top: 0px; clip: rect(1px, 1px, 1px, 1px); overflow: hidden !important; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;">λ=<span style="background-color: rgb(255, 255, 255); font-size: 14px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;">0</span></span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;"><span style="font-size: 14px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">时</span>，即没有先验, 没有正则项，则相当于先验分布具有无穷大的协方差，那么这个先验约束则会非常弱，模型为了拟合所有的训练集数据， 参数</span><span style="box-sizing: border-box; outline: 0px; font-size: 14px; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: 0px; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; word-break: break-all; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); top: 0px; clip: rect(1px, 1px, 1px, 1px); overflow: hidden !important; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;">w</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">可以变得任意大从而使得模型不稳定，即方差大而偏差小。</span><span style="box-sizing: border-box; outline: 0px; font-size: 16.8px; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: 0px; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; word-break: break-all; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; clip: rect(1.461em, 1000.37em, 2.451em, -999.997em); top: -2.289em; color: rgb(51, 51, 51); font-family: STIXGeneral-Italic; font-variant-caps: normal; font-variant-ligatures: normal; line-height: normal;">λ</span><span style="font-size: 14px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal;">越大，标明先验分布协方差越小，偏差越大，模型越稳定。即，加入正则项是在偏差bias与方差variance之间做平衡tradeoff</span></div></li></ul></ul><div><br/></div><ul><li><div><span style="font-size: 18px;">dropout: 可以看作一种模型集成</span></div></li></ul><div><br/></div><div><span style="font-size: 18px; color: rgb(255, 38, 0);">在线学习：</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="color: rgb(102, 102, 102); font-variant-caps: normal; font-variant-ligatures: normal; font-family: &quot;Helvetica Neue&quot;; font-size: 14px;">Online Learning并不是一种模型，而是一种模型的训练方法，Online Learning能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。</span></span></div><div>实时增量训练的必要性：</div><ul><li><div>每天亿级别的用户日志数据</div></li><li><div>上亿的模型参数需要更新</div></li><li><div>每天进行海量的模型预测</div></li><li><div>可以更好的学习用户实时的兴趣或者商品的实时变化趋势</div></li></ul><div><br/></div><div><br/></div><div><font style="font-size: 18px;"><span style="font-size: 18px; font-weight: bold;">传统的batch 算法</span></font>：<font style="font-size: 14px;" face="Helvetica Neue"><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(26, 26, 26); font-variant-caps: normal; font-variant-ligatures: normal;">批量算法中每次迭代对全体训练数据集进行计算（例如计算全局梯度），</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(26, 26, 26); font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">优点是精度和收敛还可以，缺点是无法有效处理大数据集（此时全局梯度计算代价太大），且没法应用于数据流做在线学习。</span></font></div><div><br/></div><div><span style="font-size: 18px;">传统的在线算法：SGD</span></div><div><font style="font-size: 14px;" face="Helvetica Neue"><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(26, 26, 26); font-variant-caps: normal; font-variant-ligatures: normal;">在线学习算法的特点是：</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(170, 121, 66); font-variant-caps: normal; font-variant-ligatures: normal;">每来一个训练样本，就用该样本产生的loss和梯度对模型迭代一次</span></span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(26, 26, 26); font-variant-caps: normal; font-variant-ligatures: normal;">，一个个数据地进行训练，</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(255, 38, 0); font-variant-caps: normal; font-variant-ligatures: normal;">因此可以处理大数据量训练和在线训练</span></span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(26, 26, 26); font-variant-caps: normal; font-variant-ligatures: normal;">。常用的有在线梯度下降（OGD）和随机梯度下降（SGD）等，本质思想是对上面【问题描述】中的</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(26, 26, 26); font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">未加和的单个数据的loss函数 L（w，zi)做梯度下降，</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(170, 121, 66); font-variant-caps: normal; font-variant-ligatures: normal;">因为每一步的方向并不是全局最优的，所以整体呈现出来的会是一个看似随机的下降路线。</span></span></font></div><div><span style="font-size: 18px;">缺点：</span></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">简单的在线梯度下降很难产生真正稀疏的解，稀疏性在机器学习中是很看重的事情</span><span style="font-size: 14px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">，尤其在工程应用，</span><span style="font-size: 14px; color: rgb(170, 121, 66); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">稀疏的特征会大大减少predict时的内存和复杂度</span><span style="color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">。这一点其实很容易理解，即便加入L1范数，因为是浮点运算，训练出的w向量也很难出现绝对的零。到这里，大家可能会想说当计算出的w对应维度的值很小时，就强制置为零不就稀疏了吗！</span><span style="letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: pre-wrap;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 250, 165);-evernote-highlight:true;"><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">其中对online learning最重要的问题是SGD很难得到需要的正则化设计的解，特别是几乎得不到稀疏解</span></span></span></div></li><li><div><span style="caret-color: rgb(26, 26, 26); font-size: 16px; color: rgb(26, 26, 26);">精度低、收敛慢</span></div></li></ul><div><br/></div><div style="text-align: center; "><div><img src="%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AD%89%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95.resources/CB3E3F39-12DC-405E-9409-AC17ABF88FF0.jpg" height="355" width="720"/><br/></div></div><div><span style="background-color: rgb(255, 250, 165);font-size: 18px;-evernote-highlight:true;">在线学习与FTRL（</span><span style="font-size: 1.2em; orphans: 2; white-space: pre-wrap; widows: 2; background-color: rgb(255, 250, 165); color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;-evernote-highlight:true;">FOLLOW THE REGULARIZED LEADER</span><span style="font-size: 18px;background-color: rgb(255, 250, 165);-evernote-highlight:true;">）</span></div><div><span style="font-size: 16px;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: pre-wrap;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;-en-paragraph:true;"><span style="font-size: 16px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">传统的批量（batch）算法无法有效地处理超大规模的数据集和在线数据流，</span></span><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-en-paragraph:true;"> Google 公司先后三年时间（2010年开始）从理论研究到实际工程化实现的 </span><span style="font-size: 16px;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: pre-wrap;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;-en-paragraph:true;"><span style="font-size: 16px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">FTRL</span></span><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-en-paragraph:true;">（Follow-the-regularized-Leader）</span><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: pre-wrap; widows: 2; word-spacing: 0px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">算法，在处理诸如</span><span style="background-color: rgb(255, 250, 165); font-size: 16px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">逻辑回归之类的带非光滑正则化项（例如 L1 范数，做模型复杂度控制和稀疏化）的凸优化问题上性能非常出色</span><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: pre-wrap; widows: 2; word-spacing: 0px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">。
</span></div><div style="font-size: 16px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; margin-top: 1em; margin-bottom: 1em;"><span style="font-size: 16px;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: pre-wrap;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;-en-paragraph:true;"><span style="background-color: rgb(255, 255, 255); font-size: 16px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">通常，优化算法中的 gradient descent 等解法，是对一批样本进行一次求解，得到一个全局最优解。</span><span style="background-color: rgb(255, 250, 165); font-size: 16px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">但是，实际的互联网广告应用需要的是快速地进行模型的更新</span><span style="font-size: 16px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">。为了保证快速的更新，训练样本是一条一条地过来的，每来一个样本，模型的参数对这个样本进行一次迭代，从而保证了模型的及时更新，这种方法叫做</span><span style="font-size: 16px; color: rgb(170, 121, 66); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">在线梯度下降法</span><span style="font-size: 16px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">（</span></span><span style="background-color: rgb(255, 255, 255); font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-en-paragraph:true;">Online Gradient Descent</span><span style="background-color: rgb(255, 255, 255); font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-en-paragraph:true;">）。
</span></div><div style="font-size: 16px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); margin-top: 1em; margin-bottom: 1em;"><span style="font-size: 16px;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: pre-wrap;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;-en-paragraph:true;"><span style="font-size: 16px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">在应用的时候，线上来的每一个广告请求，都提取出相应的特征，再根据模型的参数，计算一个点击某广告的概率。在线学习的任务就是学习模型的参数。所谓的模型的参数，其实可以认为是一个目标函数的解。跟之前说的根据批量的样本计算一个全局最优解的方法的不同是，解这个问题只能扫描一次样本，而且样本是一条一条地过来的。
</span></span></div><div><span style="font-size: 16px;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: pre-wrap;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;-en-paragraph:true;"><span style="font-size: 16px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">当然这会有误差，所以为了避免这种误差，又为了增加稀疏性，有人又想到了多个版本的算法，Google 公司有人总结了其中几种比较优秀的，例如 FOBOS，AOGD 和微软的 RDA，同时提出了 Google 自己的算法 FTRL-Proximal。其中，FTRL-Proximal 在稀疏性和精确度等方面表现都比较好。</span></span><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;-en-paragraph:true;"
/></div><div><br/></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(26, 26, 26); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">引入 L2 正则化并没有对 FTRL 的稀疏性产生影响（采用的混合正则L1+L2）</span></span></div></li><li><div style="orphans: 2; widows: 2; text-align: left;"><span style="orphans: 2; widows: 2; letter-spacing: 0.544px; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(51, 51, 51); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">FTRL，较SGD有以下优势：</span></span></div></li><ul><li><div style="orphans: 2; widows: 2; text-align: left;"><span style="orphans: 2; widows: 2; font-size: 14px; letter-spacing: normal; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(66, 99, 6); font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">带有L1正则，学习的特征更加稀疏</span></div></li><li><div style="orphans: 2; widows: 2; text-align: left;"><span style="orphans: 2; widows: 2; font-size: 14px; letter-spacing: normal; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(170, 121, 66); font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">使用累计的梯度，加速收敛</span></div></li><li><div style="orphans: 2; widows: 2; text-align: left;"><span style="font-size: 13.92px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(102, 102, 102); font-family: &quot;Hiragino Sans GB&quot;, &quot;Microsoft Yahei&quot;, 微软雅黑, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">就是每次找到让之前所有损失函数之和最小的参数</span></div></li></ul><ul><li><div style="orphans: 2; widows: 2; text-align: left;"><span style="color: rgb(66, 99, 6); font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; font-size: 14px; font-variant-caps: normal; font-variant-ligatures: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; widows: 2; word-spacing: 0px;">根据特征在样本的出现频率确定该特征学习率，</span><span style="orphans: 2; widows: 2; font-size: 14px; letter-spacing: 0.544px; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(170, 121, 66); font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">FM模型中的特征出现的频次相差很大， <span style="orphans: 2; widows: 2; font-size: 14px; letter-spacing: 0.544px; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(170, 121, 66); font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">FTRL能够</span></span><span style="color: rgb(66, 99, 6); font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; font-size: 14px; font-variant-caps: normal; font-variant-ligatures: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; widows: 2; word-spacing: 0px;">保证每个特征有充分的学习</span></div></li></ul></ul><div><br/></div><div><span style="font-size: 18px;">工程上的小技巧：</span></div><div><br/></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 250, 165); color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">1.saving memory</span></div><ul><li><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">方案1）Poisson Inclusion：对某一维度特征所来的训练样本，以p的概率接受并更新模型。</span></div></li><li><div><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">方案2）Bloom Filter Inclusion：用bloom filter从概率上做某一特征出现k次才更新。</span></div></li></ul><div><br/></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 250, 165); color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">2.浮点数重新编码</span></div><ul><li><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">特征权重不需要用32bit或64bit的浮点数存储，存储浪费空间</span></div></li><li><div><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">16bit encoding，但是要注意处理rounding技术对regret带来的影响</span></div></li></ul><div><br/></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 250, 165); color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">3.训练若干相似model</span></div><ul><li><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">对同一份训练数据序列，同时训练多个相似的model</span></div></li><li><div><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">这些model有各自独享的一些feature，也有一些共享的feature</span></div></li><li><div><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">出发点：有的特征维度可以是各个模型独享的，而有的各个模型共享的特征，可以用同样的数据训练。</span></div></li></ul><div><br/></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 250, 165); color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">4.Single Value Structure</span></div><ul><li><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">多个model公用一个feature存储（例如放到cbase或redis中），各个model都更新这个共有的feature结构</span></div></li><li><div><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">对于某一个model，对于他所训练的特征向量的某一维，直接计算一个迭代结果并与旧值做一个平均</span></div></li></ul><div><br/></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">5.使用正负样本的数目来计算梯度的和（所有的model具有同样的N和P）</span></div><div><br/></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">6.subsampling Training Data</span></div><ul><li><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">在实际中，CTR远小于50%，所以正样本更加有价值。通过对训练数据集进行subsampling，可以大大减小训练数据集的大小</span></div></li><li><div><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2;"><span style="font-size: 16px; color: rgb(255, 38, 0); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">正样本全部采</span></span><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">（至少有一个广告被点击的query数据），</span><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2;"><span style="font-size: 16px; color: rgb(255, 38, 0); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">负样本使用一个比例r采样</span></span><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">（完全没有广告被点击的query数据）。但是直接在这种采样上进行训练，会导致比较大的biased prediction，</span><span style="font-size: 16px; orphans: 2; white-space: pre-wrap; widows: 2;"><span style="font-size: 16px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">解决办法：</span><span style="font-size: 16px; color: rgb(4, 51, 255); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold;">训练的时候，对样本再乘一个权重。权重直接乘到loss上面，从而梯度也会乘以这个权重</span><span style="font-size: 16px; color: rgb(26, 26, 26); font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">。</span></span></div></li></ul><div><br/></div><div><span style="font-size: 18px;">参考链接：</span></div><ul><li><div><a href="https://blog.csdn.net/heyongluoyao8/article/details/49429629">机器学习中处理过拟合的方法</a></div></li><li><div><a href="https://tech.meituan.com/online-learning.html">Online Learning算法理论与实践（FTRL-BPR-reRanking</a>） </div></li><li><div><a href="https://zhuanlan.zhihu.com/p/32903540">FTRL算法总结 </a>                                                                     </div></li><li><div><a href="https://zhuanlan.zhihu.com/p/20447450">在线学习FTRL算法介绍</a>                                                        </div></li><li><div><a href="https://zhuanlan.zhihu.com/p/27940348">FTRL算法并行化-1 </a>                                                              </div></li><li><div><a href="http://www.doesbetter.com/852/">FTRL算法并行化-2 </a>   </div></li><li><div><a href="https://cs.nju.edu.cn/zlj/Talk/2017_ISICDM.pdf">在线学习</a></div></li><li><div><br/></div></li><li><div><a href="http://www.cnblogs.com/wei-li/p/Petuum.html">简短了解分布式计算:Petuum   </a>                                           </div></li><li><div><a href="http://www.sohu.com/a/142627311_470008">大规模机器学习的编程技术、计算模型以及Xgboost和MXNet案例</a>  </div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21569493">Parameter Server 详解</a> </div></li></ul><div><br/></div><div><br/></div></body></html>