<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.1.1 (456663)"/><meta name="altitude" content="11.52182960510254"/><meta name="author" content="杨文家"/><meta name="created" content="2018-05-20 06:30:03 +0000"/><meta name="latitude" content="30.19550091753597"/><meta name="longitude" content="120.1920272825884"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2018-06-05 14:15:37 +0000"/><title>其他</title></head><body><div><span style="-webkit-margin-before: 0px; -webkit-margin-after: 0px; border: 0px; outline: 0px; font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250); color: rgb(65, 63, 63); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">生成模型 (对联合分布建模)：</span><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250); color: rgb(65, 63, 63); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">由数据学习联合概率密度分布P(X,Y)，求出条件概率分布P(Y|X)作为预测的模型，即生成模型P(Y|X)=P(X,Y)/P(X)，再利用它分类。比如朴素贝叶斯、HMM、EM</span></div><div><br/></div><div><div><span style="font-size: 16px; color: rgb(79, 79, 79); font-weight: bold;">生成模型的优点： </span></div><ul><li><div style="box-sizing: border-box; outline: 0px; padding: 0px; list-style-type: decimal; word-break: break-all;"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; font-size: 16px; color: rgb(79, 79, 79);">生成方法的学习收敛的速度会更快。即当样本容量增加的时候，学习到的数据可以更快的收敛于真实的模型</span></div></li><li><div style="box-sizing: border-box; outline: 0px; padding: 0px; list-style-type: decimal; word-break: break-all;"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; font-size: 16px; color: rgb(79, 79, 79);">当存在隐变量时，仍然可以用生成方法，这个时候判别方法实际上是不能用的。</span></div></li></ul></div><div><span style="box-sizing: border-box; outline: 0px; word-break: break-all; font-size: 16px; color: rgb(79, 79, 79);">生成模型的缺点：生成模型会对于数据的分布的假设的要求会更高，如果数据的分布不符合假设，那么就会导致效果比较差【鲁棒性差】</span></div><div><br/></div><hr/><div><br/></div><div><span style="-webkit-margin-before: 0px; -webkit-margin-after: 0px; border: 0px; outline: 0px; font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250); color: rgb(65, 63, 63); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">判别模型（对条件分布建模）：</span><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250); color: rgb(65, 63, 63); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">由数据直接学习决策函数y=f(x)或者条件概率分布P（Y|X）作为预测的模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。</span></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250); color: rgb(65, 63, 63); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">典型的判别模型包括K近邻、感知机、决策树、支持向量机， CRF等。</span></div><div><span style="font-size: 16px; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250); color: rgb(65, 63, 63); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">由生成模型可以得到判别模型，但由判别模型得不到生成模型。生成模型学习联合概率分布P(X,Y),而判别模型学习条件概率分布P(Y|X)</span></div><div><br/></div><div><span style="font-size: 16px; color: rgb(79, 79, 79); font-weight: bold;">判别模型优点： </span></div><ul><li><div style="box-sizing: border-box; outline: 0px; padding: 0px; list-style-type: decimal; word-break: break-all;"><span style="box-sizing: border-box; outline: 0px; word-break: break-all;"><span style="font-size: 14px; color: rgb(79, 79, 79);">判别模型对数据的分布的假设要求不高，鲁棒性较好，即便是在模型不符合数据假设的情况下，效果通常也会比较好</span></span></div></li><li><div style="box-sizing: border-box; outline: 0px; padding: 0px; list-style-type: decimal; word-break: break-all;"><span style="box-sizing: border-box; outline: 0px; word-break: break-all;"><span style="font-size: 14px; color: rgb(79, 79, 79);">直接面对预测，往往在学习的准确率上会更高</span></span></div></li><li><div style="box-sizing: border-box; outline: 0px; padding: 0px; list-style-type: decimal; word-break: break-all;"><font style="font-size: 14px;"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; font-size: 14px; color: rgb(79, 79, 79);">由于直接学习</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1002.45em, 2.659em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Italic; line-height: normal;">P</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1002.45em, 2.659em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Regular; line-height: normal;">(</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1002.45em, 2.659em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Italic; line-height: normal;">Y</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1002.45em, 2.659em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXVariants; line-height: normal;">|</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1002.45em, 2.659em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Italic; line-height: normal;">X</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1002.45em, 2.659em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Regular; line-height: normal;">)</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; top: 0px; clip: rect(1px, 1px, 1px, 1px); font-size: 14px; overflow: hidden !important; color: rgb(79, 79, 79); line-height: normal;">P(Y|X)</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; font-size: 14px; color: rgb(79, 79, 79);">或者</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1001.46em, 2.607em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Italic; line-height: normal;">F</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1001.46em, 2.607em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Regular; line-height: normal;">(</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1001.46em, 2.607em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Italic; line-height: normal;">x</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; clip: rect(1.461em, 1001.46em, 2.607em, -999.997em); top: -2.289em; font-size: 14px; color: rgb(79, 79, 79); font-family: STIXGeneral-Regular; line-height: normal;">)</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; text-indent: 0px; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; top: 0px; clip: rect(1px, 1px, 1px, 1px); font-size: 14px; overflow: hidden !important; color: rgb(79, 79, 79); line-height: normal;">F(x)</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; font-size: 14px; color: rgb(79, 79, 79);">，可以对数据进行各种程度上的抽象，定义特征并且使用特征，因此可以简化学习的问题。</span></font></div></li></ul><div><span style="box-sizing: border-box; outline: 0px; word-break: break-all;"><span style="font-size: 14px; color: rgb(79, 79, 79);">判别模型的缺点：如果数据分布符合生成模型假设的情况下，判别模型效果并没有生成模型好。 存在隐变量时不能用。</span></span></div><div><br/></div><hr/><h1 style="box-sizing: border-box; outline: 0px; padding: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 18px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold; line-height: 36px;">生成模型和判别模型的区别和联系
</span></span></h1><ul><li><div><b style="font-size: 14px;"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; font-size: 14px; font-weight: bold; color: rgb(79, 79, 79);">由生成模型可以得到判别模型,但是由判别模型得不到生成模型</span></b></div></li><li><div><span style="box-sizing: border-box; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-weight: bold;">生成模型可以</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-weight: bold;">产生</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-weight: bold;">数据，判别模型只能根据数据做判断。生成模型为了</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-weight: bold;">得到数据的整体分布</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-weight: bold;">。判别模型为了</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-weight: bold;">用「线」把数据划开</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-weight: bold;">。</span></div></li></ul><div><br/></div><hr/><div style="box-sizing: border-box; outline: 0px; padding: 0px; list-style-type: decimal; word-break: break-all;"><h3 style="-webkit-margin-before: 0px; -webkit-margin-after: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 22.4px; -webkit-font-smoothing: antialiased; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250);"><span style="-webkit-margin-before: 0px; -webkit-margin-after: 0px; border: 0px; outline: 0px; font-size: 22.4px; -webkit-font-smoothing: antialiased; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250); color: rgb(51, 51, 51); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold; line-height: 1em;">KNN
</span></h3><div><br/></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(250, 250, 250);"><span style="background-color: rgb(250, 250, 250); font-size: 14px; color: rgb(65, 63, 63); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">k近邻模型的三个基本要素：距离度量，k值的选择，分类决策规则。常用的距离度量是欧式距离及更一般的Lp距离。k值小时，k近邻模型更复杂；k值大时，k近邻模型更简单。k值的选择反映了对近似误差与估计误差之间的权衡，通常由交叉验证选择最优的k。常用的分类决策规则是多数表决，对应于经验风险最小化。</span></span></div><div><br/></div><div><span style="color: rgb(79, 79, 79);">优点：</span></div><ul><li><div><span style="color: rgb(79, 79, 79);">简单，易于理解，易于实现，</span><span style="background-color: rgb(255, 250, 165); color: rgb(79, 79, 79);-evernote-highlight:true;">无需估计参数，无需训练</span><span style="color: rgb(79, 79, 79);">。</span></div></li><li><div><span style="color: rgb(79, 79, 79);">特别适合于多分类问题(multi-modal,对象具有多个类别标签)， kNN比SVM的表现要好。</span></div></li></ul><div><br style="color: rgb(79, 79, 79);"/></div><div><span style="color: rgb(79, 79, 79);">缺点：</span></div><ul><li><div><span style="color: rgb(79, 79, 79);">该算法在分类时的不足<span style="font-size: 14px; color: rgb(79, 79, 79);">是，</span></span><font style="font-size: 14px;"><span style="-webkit-margin-before: 0px; -webkit-margin-after: 0px; border: 0px; outline: 0px;"><span style="font-size: 14px; color: rgb(255, 38, 0);">当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数</span></span><span style="-webkit-margin-before: 0px; -webkit-margin-after: 0px; border: 0px; outline: 0px; font-size: 14px; color: rgb(79, 79, 79);">。</span><span style="font-size: 14px; color: rgb(79, 79, 79);"> 该算法只计算“最近的”邻居样本，某一类的样本数量很大，那么或者这类样本并不接近目标样本，或者这类样本很靠近目标样本。</span><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(79, 79, 79);-evernote-highlight:true;">无论怎样，数量并不能影响运行结果</span><span style="font-size: 14px; color: rgb(79, 79, 79);">。</span></font></div></li><li><div><span style="color: rgb(79, 79, 79);">该方法的另一个不足之处是</span><span style="-webkit-margin-before: 0px; -webkit-margin-after: 0px; border: 0px; outline: 0px; font-size: 16px;"><span style="font-size: 16px; color: rgb(255, 38, 0);">计算量较大</span></span><span style="color: rgb(79, 79, 79);">，因为对每一个待分类的文本都要计算它到全体已知样本的距离，才能求得它的K个最近邻点。</span></div></li><li><div><font color="#4f4f4f">K怎么选择</font><font face="Helvetica Neue"><font color="#4f4f4f">：</font><span style="font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font color="#ff2600">k 值太小容易产生过拟合</font></span><span style="font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font color="#555555">，因为它很容易学到噪声，比如说 k=1，那么就只用看和输入 instance 最邻近的一个 instance；</font><span style="font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font style="font-size: 14px;"><font color="#ff2600">k 值太大，那么意味着你的模型变得更加的简单</font><font color="#555555">，比如说 k=N(N为训练样本的个数)，</font><font color="#ff2600">那么无论输入的 instance 是什么类别，都会归到训练集中 instance 最多的那个类</font><font color="#555555">，也就是说，根本没有进行训练，只是简单的 count 而已，并没有利用训练集的其他大量的有用信息。</font></font></span></span></font></div></li></ul><div>文本分类，聚类，多分类</div><div><br/></div><div>鞍点，计算该点的Hessian矩阵，如果矩阵是不定的，即为鞍点</div><div>看矩阵的特征值</div><div>对于任意n维向量x，有x^T*A*x &gt;0 ，则为正定</div></div><div><br/></div></body></html>