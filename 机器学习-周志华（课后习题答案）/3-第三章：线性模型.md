---
typora-copy-images-to: ./picture
---

## 习题

### 3.1 

试分析在什么情况下，在以下式子中不比考虑偏置项b

答：线性模型$y=w^tx+b$，两个实例相减得到$y_i−y_0=w^t(x_i−x_0)$以此消除了b。所以可以对训练集每个样本都减去第一个样本，然后对新的样本做线性回归，只需要用模型$y=w^tx$。

### 3.2 

试证明对于参数$w$，对率回归$（logistics回归）$的目标函数（式1）是非凸的，但其对数似然函数（式2）是凸的。

**答** ：如果一个多元函数是凸的，那么它的$Hessian$矩阵是半正定的。
$$
\begin{align*}
& y = \frac{1}{1+e^{-w^Tx+b}} \\
& \frac{dy}{dw} = \frac{xe^{-(w^Tx+b)}}{(1+e^{-(w^Txb)})^2=x(y-y^2)}\\
& \frac{d}{dw^T}(\frac{dy}{dw})=x(1-2y)(\frac{dy}{dw})^T =xx^Ty(y-1)(1-2y)\\
\end{align*}
$$

$xx^T$合同于单位矩阵，所以$xx^T$是半正定矩阵 
y的值域为$(0,1)$,当$y∈(0.5,1)$时，$y(y−1)(1−2y)<0$,导致$\frac{d}{dw^T}(\frac{dy}{dw})$半负定，所以$y=\frac{1}{1+e^{-(w^Tx+b)}}$是非凸的。

概率$p1∈(0,1)$，则$p1(x;β)(1−p1(x;β))≥0$，所以$l(β)=∑m_i=1(−y_iβ^Tx_i+ln(1+e^{β^Tx}))$是凸函数。

### 3.3 

编程实现对率回归，并给出西瓜数据集3.0α上的结果

详细见[code](https://github.com/BranY/Notes/tree/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%91%A8%E5%BF%97%E5%8D%8E%EF%BC%88%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E7%AD%94%E6%A1%88%EF%BC%89/code)  [nbviewer](http://nbviewer.jupyter.org/github/BranY/Notes/tree/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%91%A8%E5%BF%97%E5%8D%8E%EF%BC%88%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E7%AD%94%E6%A1%88%EF%BC%89/code/])

## 参考链接

[1.周志华《机器学习》课后习题解答系列（一）：目录](http://blog.csdn.net/snoopy_yuan/article/details/62045353)

[2. 机器学习(周志华西瓜书)参考答案总目录](http://blog.csdn.net/icefire_tyh/article/details/52064910)

[3.机器学习(周志华) 参考答案 第三章 线性模型](http://blog.csdn.net/icefire_tyh/article/details/52069025)

