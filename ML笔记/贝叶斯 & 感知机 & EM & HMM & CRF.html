<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.1.1 (456663)"/><meta name="altitude" content="11.38462257385254"/><meta name="author" content="杨文家"/><meta name="created" content="2018-05-19 12:47:42 +0000"/><meta name="latitude" content="30.19547523312549"/><meta name="longitude" content="120.1919652606613"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2018-05-21 02:34:32 +0000"/><title>贝叶斯 &amp; 感知机 &amp; EM &amp; HMM &amp; CRF</title></head><body><div><br/></div><div><img src="%E8%B4%9D%E5%8F%B6%E6%96%AF%20&amp;%20%E6%84%9F%E7%9F%A5%E6%9C%BA%20&amp;%20EM%20&amp;%20HMM%20&amp;%20CRF.resources/F95EFD45-ED39-4913-8150-A6E59B7E5B5D.png" height="342" width="1388"/><br/></div><div><br/></div><div>1.朴素贝叶斯和LR的区别是啥</div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font style="font-size: 14px;"><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">朴素贝叶斯是生成模型</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">，根据已有样本进行贝叶斯估计</span><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">学习出先验概率</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">P(Y)和</span><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">条件概率</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">P(X|Y)，进而求出联合分布概率P(XY),最后利用贝叶斯定理求解P(Y|X)， 而</span><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">LR是判别模型，根据极大化对数似然函数直接求出条件概率</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">P(Y|X)；</span></font></span></div></li><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font style="font-size: 14px;"><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">朴素贝叶斯是基于很强的条件独立假设（在已知分类Y的条件下，各个特征变量取值是相互独立的），而LR则对此没有要求；</span></font></span></div></li><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font style="font-size: 14px;"><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。</span></font></span></div></li></ul><div><span style="caret-color: rgb(79, 79, 79); color: rgb(79, 79, 79);">朴素贝叶斯方法的优缺点：</span></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">对小规模的数据表现很好，适合多分类任务，适合增量式训练。</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">样本容量增加时，收敛更快；隐变量存在时也可适用。</span></span></span></div></li><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）</span></span></div></li><li><div><span style="caret-color: rgb(79, 79, 79); font-size: 14px; color: rgb(79, 79, 79);">由于样本属性独立性假设，如果属性存在很强关联效果不好</span></div></li><li><div><span style="caret-color: rgb(79, 79, 79); font-size: 14px; color: rgb(79, 79, 79);">文本分类，垃圾邮件的分类</span></div></li><li style=""><div><font color="#4f4f4f"><span style="caret-color: rgb(79, 79, 79); font-size: 14px;">多项式模型，计算先验概率和条件概率，平滑，但特征是连续性变量，多项式模型就会产生很多零概率，即使五年平滑，所得到的条件概率也很难念书真实情况; 高斯模型</span></font></div></li></ul><div><br/></div><div><span style="box-sizing: border-box;outline: 0px;word-break: break-all;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;-en-paragraph:true;"><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;">LR 不关心样本中类别的比例及类别下出现特征的概率，它直接给出预测模型的式子。设每个特征都有一个权重，训练样本数据更新权重w，得出最终表达式。梯度法。</span></span></div><ul><li><div><span style="font-size: 14px; orphans: 2; text-align: justify; widows: 2; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal; line-height: 26px; text-decoration: underline;-en-paragraph:true;">优点：</span><span style="font-size: 14px; orphans: 2; text-align: justify; widows: 2; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">直接预测往往准确率更高；简化问题；可以反应数据的分布情况，类别的差异特征；适用于较多类别的识别。</span></div></li><li><div><span style="font-size: 14px; outline: 0px; word-break: break-all; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal; line-height: 26px; text-decoration: underline;-en-paragraph:true;">缺点：</span><span style="font-size: 14px; outline: 0px; word-break: break-all; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">收敛慢；不适用于有隐变量的情况。</span></div></li></ul><div><br/></div><div>2.朴素贝叶斯的朴素体现在哪里</div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><font style="font-size: 14px;" face="Helvetica Neue"><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(79, 79, 79); font-variant-caps: normal; font-variant-ligatures: normal;">利用贝叶斯定理求解联合概率P(XY)时，需要计算条件概率P(X|Y)。在计算P(X|Y)时，朴素贝叶斯做了一个很强的条件独立假设（</span><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(255, 38, 0); font-variant-caps: normal; font-variant-ligatures: normal;">当Y确定时，X的各个分量取值之间相互独立</span><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(79, 79, 79); font-variant-caps: normal; font-variant-ligatures: normal;">），即P(X1=x1,X2=x2,...Xj=xj|Y=yk) = P(X1=x1|Y=yk)*P(X2=x2|Y=yk)*...*P(Xj=xj|Y=yk)</span></font></span></div><div><br/></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">3.朴素贝叶斯在估计条件概率P(X|Y)时出现0概率怎么办？能怎么办，当然是引入平滑啊</span></span></div><div><br/></div><div>4.贝叶斯分类器与贝叶斯学习的不同 ？<span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="background-color: rgb(255, 250, 165); font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;-evernote-highlight:true;">通过最大后验概率进行单点估计；后者：进行分布估计</span><span style="font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">。</span></span></div><div><br/></div><div>5.为什么属性独立性假设在实际任务中很难成立，但是朴素贝叶斯依然可以取的很好的效果？</div><ul><li><div><span style="box-sizing: border-box; outline: 0px; font-size: 14px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(79, 79, 79); font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">对于分类任务来说</span><span style="box-sizing: border-box;outline: 0px;font-size: 14px;word-break: break-all;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);-en-paragraph:true;"><span style="background-color: rgb(255, 255, 255); font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;">，只要各类别的条件概率排序正确、无需精准概率值即可导致正确分类</span></span><span style="box-sizing: border-box; outline: 0px; font-size: 14px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(79, 79, 79); font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">； </span></div></li><li><div><span style="font-size: 14px; orphans: 2; widows: 2;"><span style="font-size: 14px; color: rgb(255, 38, 0); font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun;">如果属性间依赖对所有类别影响相同，或依赖关系的影响能相互抵消</span></span><span style="font-size: 14px; orphans: 2; widows: 2; color: rgb(79, 79, 79); font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun;">，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响。</span></div></li></ul><div><br/></div><div><span style="font-size: 14px; font-family: &quot;Helvetica Neue&quot;;">EM算法：</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">有时候任务中含有一些不能观察到的隐含变量，样本的产生和隐含变量有关，而求模型的参数时一般用最大似然估计，由于隐变量的存在，所以对似然函数参数求导是求不出来的，这时采用</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">EM算法来求导。</span></div><div><span style="font-size: 14px; orphans: 2; text-align: justify; widows: 2; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal; font-weight: bold; line-height: 26px;-en-paragraph:true;">总结</span><span style="font-size: 14px; orphans: 2; text-align: justify; widows: 2; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">：是一种迭代算法，用于含有隐变量的概率模型参数的极大似然估计。两个步骤交替计算：</span></div><ul><li><div style="box-sizing: border-box; outline: 0px; padding: 0px; text-align: justify; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); margin-top: 1em; margin-bottom: 1em;"><font style="font-size: 14px;" face="Helvetica Neue"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(79, 79, 79); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">E步：利用当前估计的参数值，求出在该参数下隐含变量的条件概率值（计算</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(79, 79, 79); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px; text-decoration: underline;-en-paragraph:true;">对数似然的期望值）</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(79, 79, 79); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">； </span></font></div></li><li><div style="box-sizing: border-box; outline: 0px; padding: 0px; text-align: justify; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); margin-top: 1em; margin-bottom: 1em;"><span style="font-size: 14px; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">M步：结合E步求出的隐含变量条件概率，求出似然函数下界函数的最大值（寻找能使E步产生的似然期望最大化的</span><span style="font-size: 14px; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px; text-decoration: underline;-en-paragraph:true;">参数值</span><span style="font-size: 14px; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">。）然后，新得到的参数值重新被用于</span><span style="font-size: 14px; outline: 0px; word-break: break-all; color: rgb(79, 79, 79); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">E步.....直到收敛到局部最优解。（note：每次迭代实际在求Q函数及其极大，即每次迭代使似然函数增大或达到局部极值。）</span></div></li></ul><div style="box-sizing: border-box; outline: 0px; padding: 0px; text-align: justify; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); margin-top: 1em; margin-bottom: 1em;"><font style="font-size: 14px;" face="Helvetica Neue"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(79, 79, 79); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">通俗来讲：就是对于一个含有隐变量的概率模型，目标是极大化观测数据</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(79, 79, 79); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">Y关于参数theta的对数似然函数。
</span></font></div><div style="box-sizing: border-box; outline: 0px; padding: 0px; text-align: justify; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); margin-top: 1em; margin-bottom: 1em;"><font style="font-size: 14px;" face="Helvetica Neue"><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(223, 64, 42); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">优点：简单性和普适性，可看作是一种非梯度优化方法（解决梯度下降等优化方法的缺陷：求和的项数将随</span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(223, 64, 42); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">  </span><span style="box-sizing: border-box; outline: 0px; word-break: break-all; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); font-size: 14px; font-family: &quot;Helvetica Neue&quot;; color: rgb(223, 64, 42); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;-en-paragraph:true;">着隐变量的数目以指数级上升，会给梯度计算带来麻烦）</span></font></div><div><span style="box-sizing: border-box;outline: 0px;word-break: break-all;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;-en-paragraph:true;"><span style="font-size: 14px; color: rgb(223, 64, 42); font-family: &quot;Helvetica Neue&quot;; font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;">缺点：对初始值敏感，不同的初值可能得到不同的参数估计值；不能保证找到全局最优值。</span></span></div><div><br/></div><div>参考链接：</div><ul><li><div><a href="https://blog.csdn.net/jingyi130705008/article/details/79464740">贝叶斯面试总结1</a></div></li><li><div><a href="https://blog.csdn.net/qq_34896915/article/details/75040686">贝叶斯面试总结2</a></div></li><li><div><a href="https://blog.csdn.net/qq_34896915/article/details/75040578">EM算法面试总结</a> （结合词对齐算法）</div></li><li><div><a href="http://nlp.ict.ac.cn/~liuqun/course/MachineTranslation/2010ict/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%8E%9F%E7%90%86%E4%B8%8E%E6%96%B9%E6%B3%95%E8%AE%B2%E4%B9%89(03)%E5%9F%BA%E4%BA%8E%E8%AF%8D%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%96%B9%E6%B3%95.pdf">基于词的统计机器翻译方法</a></div></li><li><div><a href="http://nlp.ict.ac.cn/~liuqun/course/MachineTranslation/">中科院计算所-机器翻译原理与方法</a></div></li><li><div><a href="http://saliormoon.github.io/2016/07/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%981/">机器学习面试问题</a></div></li></ul><div><br/></div></body></html>